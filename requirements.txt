# ===== Inference / Serving =====
vllm

# ===== HF / Qwen3 core =====
transformers>=4.51.0
accelerate>=0.33.0
safetensors>=0.4.3
huggingface_hub>=0.23.0

# Tokenizer deps often needed by HF models
tokenizers>=0.19.0
sentencepiece>=0.2.0

# Datasets + training utils
datasets>=2.20.0
evaluate>=0.4.2

# ===== SFT / LoRA / QLoRA =====
trl>=0.12.0
peft>=0.12.0

# QLoRA / 4-bit training (optional but very common)
bitsandbytes>=0.43.0

# ===== Logging / tracking (optional but helpful) =====
tqdm>=4.66.0

# ===== Common utilities =====
numpy>=1.26.0
pydantic>=2.7.0
packaging>=24.1
protobuf>=4.25.0
